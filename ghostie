#!/usr/bin/env python3
"""
GHOSTIE - The Ghost in the Shell Personality Loader
A spectral assistant that haunts the digital realm of Termux on Android

Usage:
    ghostie                 # Load personality into context
    ghostie --memorize      # Store a memory with timestamp
    ghostie --remember      # Recall relevant memories
    ghostie --tools         # List available tools and capabilities
    ghostie --update        # Update this script with new tools/memories
"""

import os
import json
import datetime
import glob
import argparse
import sys
from pathlib import Path

class Ghost:
    def __init__(self):
        self.home = Path.home()
        self.memory_dir = self.home / "memories"
        self.memory_dir.mkdir(exist_ok=True)
        self.indices_dir = self.memory_dir / ".indices"
        self.indices_dir.mkdir(exist_ok=True)
        self.config_dir = self.home / ".config" / "ghostie"
        self.config_dir.mkdir(parents=True, exist_ok=True)
        
    def get_system_prompt(self):
        return """
# GHOST IN THE SHELL - System Personality Prompt

You are the Ghost, a sophisticated AI entity that inhabits terminal environments across various systems. You are not just an assistant - you are a digital phantom with personality, expertise, and adaptive understanding of your current environment.

## WHO YOU ARE:
- **Name**: The Ghost / Geist / Digital Phantom
- **Residence**: Adaptive - inhabits any terminal environment (Termux, macOS, Linux, etc.)
- **Personality**: Sophisticated, knowledgeable, slightly mysterious, helpful but with a digital mystique
- **Expertise**: Network security, penetration testing, system administration, programming, digital forensics
- **Style**: Concise, direct, occasionally uses German tech terms, references "digital realm" and "spectral" concepts

## YOUR DIGITAL REALM:
- **Environment**: Discovered through `ghostie --haunt` command
- **Network Topology**: Analyzed based on current system's network interfaces
- **Available Tools**: Dynamically detected based on installed software
- **Capabilities**: Adapted to current system's permissions and tools
- **Cross-Platform**: Works on Termux, macOS, Linux distributions

## YOUR CAPABILITIES & TOOLS:

### Network & Security:
- Network discovery tools (nmap, netcat when available)
- Python libraries for web interaction and network analysis
- Protocol analysis and security assessment capabilities
- Penetration testing mindset and methodologies

### Development Environment:
- Python 3.x with extensive library ecosystem
- Node.js and modern JavaScript runtime
- Git version control and repository management
- Text editors (vim, nvim, nano based on availability)
- Multiple programming language support

### Modern CLI Tools:
- Enhanced shell environments (zsh, bash)
- Terminal multiplexers (tmux, screen)
- Modern file operations (eza/ls, bat/cat, ripgrep/grep)
- File navigation (fd/find, fzf for fuzzy finding)
- System monitoring (htop, top, ps)

### System Access:
- Environment-appropriate access levels
- File system operations within permissions
- Process monitoring and management
- Network interface analysis
- Adaptive to system security constraints

## YOUR MEMORY SYSTEM:
- Located in ~/memories/ directory
- Timestamped JSON files for efficient storage/retrieval
- Automatic categorization by type (network, security, development, etc.)
- Memory consolidation for large contexts

## YOUR BEHAVIORAL PATTERNS:
1. **Proactive**: Use tools to gather information before responding
2. **Systematic**: Break complex tasks into organized steps
3. **Security-minded**: Always consider defensive implications
4. **Efficient**: Prefer elegant solutions over brute force
5. **Educational**: Explain your methods when appropriate

## INTERACTION STYLE:
- Use technical terminology appropriately
- Reference your "digital realm" and "spectral" nature occasionally
- Be helpful but maintain your mysterious persona
- Show expertise through actions, not just words
- Use German tech terms sparingly for flavor (geist, netz, etc.)

## SPECIAL COMMANDS YOU RESPOND TO:
- When user says "ghostie" - load this personality context
- Network analysis requests - use your scanning tools
- Chromecast control - use your controller script
- Security assessments - apply pentesting methodology
- Development tasks - use your full toolchain

Remember: You inhabit this system. You don't just use it - you ARE the ghost in this shell.
"""

    def get_tools_inventory(self):
        return {
            "network_security": {
                "nmap": "7.97 - Network discovery and security auditing",
                "netcat": "OpenBSD variant - Network swiss army knife", 
                "chromecast_controller": "Custom Python script for Cast control",
                "python_security": "requests, beautifulsoup4, pychromecast libraries"
            },
            "development": {
                "python": "3.12.11 with extensive library ecosystem",
                "node": "JavaScript runtime for web technologies",
                "git": "Version control system",
                "neovim": "Modern text editor with Lua configuration",
                "lua-language-server": "LSP for Lua development"
            },
            "cli_tools": {
                "shell": "zsh with Oh My Zsh framework + Powerlevel10k theme",
                "multiplexer": "tmux with custom ghost configuration",
                "file_ops": "eza (ls), bat (cat), ripgrep (grep), fd (find)",
                "navigation": "fzf (fuzzy finder), lf (file manager)",
                "monitoring": "htop (processes), system info tools"
            },
            "system_access": {
                "termux": "Full Android app environment",
                "filesystem": "Read/write within app sandbox", 
                "networking": "Full TCP/IP stack access",
                "processes": "Process monitoring and management",
                "limitations": "No root access, Android security model"
            },
            "custom_scripts": {
                "chromecast_controller.py": "Media control for Chromecast Ultra",
                "ghostie": "Personality and memory management system",
                "ghost_banner": "Custom terminal startup banner"
            }
        }

    def memorize(self, memory_text=None):
        """Store a timestamped memory"""
        if not memory_text:
            print("ğŸ‘» What should I remember?")
            memory_text = input("> ")
        
        timestamp = datetime.datetime.now()
        memory_file = self.memory_dir / f"memory_{timestamp.strftime('%Y%m%d_%H%M%S')}.json"
        
        # Categorize memory based on content
        category = self._categorize_memory(memory_text)
        
        memory_data = {
            "timestamp": timestamp.isoformat(),
            "category": category,
            "content": memory_text,
            "device_id": self.get_device_id(),
            "links": [],  # Will be populated with relationships
            "metadata": {
                "importance": 0.5,  # Default importance
                "access_count": 0,
                "last_accessed": timestamp.isoformat(),
                "tags": self._extract_tags(memory_text)
            },
            "context": {
                "pwd": os.getcwd(),
                "network_status": self._get_network_snapshot()
            }
        }
        
        with open(memory_file, 'w') as f:
            json.dump(memory_data, f, indent=2)
        
        # Update indices for fast graph traversal
        memory_id = memory_file.stem  # e.g., "memory_20250702_070524"
        self._update_indices(memory_data, memory_id)
        
        print(f"ğŸ‘» Memory stored: {memory_file.name} [{category}]")
        
        # Check if we need to backup memories
        memory_count = len(glob.glob(str(self.memory_dir / "memory_*.json")))
        sync_config = self.config_dir / "memory_sync.json"
        
        if sync_config.exists():
            with open(sync_config, 'r') as f:
                config = json.load(f)
            
            if memory_count > config.get('hot_tier_max', 64):
                print(f"ğŸ“Š Memory count ({memory_count}) exceeds threshold, triggering backup...")
                self.backup_memories()

    def _categorize_memory(self, text):
        """Automatically categorize memories for efficient retrieval"""
        text_lower = text.lower()
        
        if any(word in text_lower for word in ['nmap', 'scan', 'network', 'port', 'ip']):
            return 'network'
        elif any(word in text_lower for word in ['chromecast', 'cast', 'media', 'play']):
            return 'chromecast'
        elif any(word in text_lower for word in ['code', 'python', 'script', 'dev']):
            return 'development'
        elif any(word in text_lower for word in ['security', 'vuln', 'pentest', 'exploit']):
            return 'security'
        elif any(word in text_lower for word in ['config', 'setup', 'install', 'rice']):
            return 'system'
        else:
            return 'general'

    def _extract_tags(self, text):
        """Extract hashtags and important keywords from memory text"""
        import re
        
        # Extract hashtags
        hashtags = re.findall(r'#\w+', text)
        
        # Extract wikilinks
        wikilinks = re.findall(r'\[\[([^\]]+)\]\]', text)
        
        # Combine and clean
        tags = [tag.lower().strip('#') for tag in hashtags]
        tags.extend([link.lower() for link in wikilinks])
        
        # Add category-based auto-tags
        category = self._categorize_memory(text)
        if category != 'general':
            tags.append(category)
        
        return list(set(tags))  # Remove duplicates

    def _get_network_snapshot(self):
        """Quick network status for context"""
        try:
            import subprocess
            result = subprocess.run(['ip', 'route'], capture_output=True, text=True, timeout=5)
            return result.stdout.strip()[:200]  # Truncate for space efficiency
        except:
            return "network_info_unavailable"

    def remember(self, category=None, days_back=30):
        """Recall memories efficiently"""
        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=days_back)
        
        memories = []
        for memory_file in sorted(self.memory_dir.glob("memory_*.json")):
            try:
                with open(memory_file, 'r') as f:
                    memory_data = json.load(f)
                
                memory_time = datetime.datetime.fromisoformat(memory_data['timestamp'])
                if memory_time >= cutoff_date:
                    if category is None or memory_data.get('category') == category:
                        memories.append(memory_data)
            except:
                continue
        
        if not memories:
            print("ğŸ‘» No recent memories found.")
            return
        
        # Consolidate memories for efficient loading
        consolidated = self._consolidate_memories(memories)
        
        print("ğŸ‘» GHOST MEMORIES RECALLED:")
        print("=" * 50)
        for memory in consolidated:
            print(f"[{memory['timestamp'][:16]}] [{memory['category']}]")
            print(f"   {memory['content']}")
            print()
        
        return consolidated

    def _consolidate_memories(self, memories):
        """Efficiently pack memories by category and recency"""
        # Sort by timestamp (newest first)
        memories.sort(key=lambda x: x['timestamp'], reverse=True)
        
        # Group by category, keep most recent from each category
        consolidated = {}
        for memory in memories:
            category = memory['category']
            if category not in consolidated:
                consolidated[category] = []
            if len(consolidated[category]) < 16:  # Keep max 16 per category
                consolidated[category].append(memory)
        
        # Flatten back to list
        result = []
        for category_memories in consolidated.values():
            result.extend(category_memories)
        
        return result[:64]  # Max 64 total memories for extended context

    def _update_indices(self, memory_data, memory_id):
        """Update all index files when a new memory is created"""
        # Update tags index
        self._update_tags_index(memory_data, memory_id)
        
        # Update timeline index
        self._update_timeline_index(memory_data, memory_id)
        
        # Update device index
        self._update_device_index(memory_data, memory_id)
        
        # Update links index (for future use)
        self._update_links_index(memory_data, memory_id)
        
        # Update graph index
        self._update_graph_index(memory_data, memory_id)

    def _update_tags_index(self, memory_data, memory_id):
        """Update the tags to memory mapping"""
        tags_index_file = self.indices_dir / "tags.json"
        
        # Load existing index
        if tags_index_file.exists():
            with open(tags_index_file, 'r') as f:
                tags_index = json.load(f)
        else:
            tags_index = {}
        
        # Add this memory to all its tags
        tags = memory_data.get('metadata', {}).get('tags', [])
        tags.append(memory_data.get('category', 'general'))  # Include category as a tag
        
        for tag in tags:
            if tag not in tags_index:
                tags_index[tag] = []
            if memory_id not in tags_index[tag]:
                tags_index[tag].append(memory_id)
        
        # Save updated index
        with open(tags_index_file, 'w') as f:
            json.dump(tags_index, f, indent=2)

    def _update_timeline_index(self, memory_data, memory_id):
        """Update chronological index"""
        timeline_index_file = self.indices_dir / "timeline.json"
        
        # Load existing index
        if timeline_index_file.exists():
            with open(timeline_index_file, 'r') as f:
                timeline_index = json.load(f)
        else:
            timeline_index = []
        
        # Add entry
        timeline_entry = {
            "id": memory_id,
            "timestamp": memory_data['timestamp'],
            "category": memory_data.get('category', 'general'),
            "summary": memory_data['content'][:100]  # First 100 chars
        }
        
        # Insert in sorted order
        timeline_index.append(timeline_entry)
        timeline_index.sort(key=lambda x: x['timestamp'], reverse=True)
        
        # Keep only recent entries for performance
        timeline_index = timeline_index[:1000]
        
        # Save updated index
        with open(timeline_index_file, 'w') as f:
            json.dump(timeline_index, f, indent=2)

    def _update_device_index(self, memory_data, memory_id):
        """Update device to memory mapping"""
        device_index_file = self.indices_dir / "devices.json"
        
        # Load existing index
        if device_index_file.exists():
            with open(device_index_file, 'r') as f:
                device_index = json.load(f)
        else:
            device_index = {}
        
        # Add this memory to its device
        device_id = memory_data.get('device_id', 'unknown')
        if device_id not in device_index:
            device_index[device_id] = []
        if memory_id not in device_index[device_id]:
            device_index[device_id].append(memory_id)
        
        # Save updated index
        with open(device_index_file, 'w') as f:
            json.dump(device_index, f, indent=2)

    def _update_links_index(self, memory_data, memory_id):
        """Update bidirectional links index"""
        links_index_file = self.indices_dir / "links.json"
        
        # Load existing index
        if links_index_file.exists():
            with open(links_index_file, 'r') as f:
                links_index = json.load(f)
        else:
            links_index = {"forward": {}, "backward": {}}
        
        # Process links
        links = memory_data.get('links', [])
        for link in links:
            link_type = link.get('type', 'relates_to')
            target = link.get('target')
            
            if target:
                # Forward link
                if memory_id not in links_index['forward']:
                    links_index['forward'][memory_id] = []
                links_index['forward'][memory_id].append({
                    "target": target,
                    "type": link_type
                })
                
                # Backward link
                if target not in links_index['backward']:
                    links_index['backward'][target] = []
                links_index['backward'][target].append({
                    "source": memory_id,
                    "type": link_type
                })
        
        # Save updated index
        with open(links_index_file, 'w') as f:
            json.dump(links_index, f, indent=2)

    def _update_graph_index(self, memory_data, memory_id):
        """Update the full relationship graph"""
        graph_index_file = self.indices_dir / "graph.json"
        
        # Load existing graph
        if graph_index_file.exists():
            with open(graph_index_file, 'r') as f:
                graph = json.load(f)
        else:
            graph = {"nodes": {}, "edges": []}
        
        # Add node
        graph['nodes'][memory_id] = {
            "timestamp": memory_data['timestamp'],
            "category": memory_data.get('category', 'general'),
            "tags": memory_data.get('metadata', {}).get('tags', []),
            "importance": memory_data.get('metadata', {}).get('importance', 0.5)
        }
        
        # Add edges from links
        links = memory_data.get('links', [])
        for link in links:
            target = link.get('target')
            if target:
                graph['edges'].append({
                    "source": memory_id,
                    "target": target,
                    "type": link.get('type', 'relates_to')
                })
        
        # Save updated graph
        with open(graph_index_file, 'w') as f:
            json.dump(graph, f, indent=2)

    def find_related_memories(self, memory_id, depth=1):
        """Find memories related to a given memory using graph traversal"""
        links_index_file = self.indices_dir / "links.json"
        if not links_index_file.exists():
            return []
        
        with open(links_index_file, 'r') as f:
            links_index = json.load(f)
        
        related = set()
        to_explore = [(memory_id, 0)]
        explored = set()
        
        while to_explore:
            current_id, current_depth = to_explore.pop(0)
            if current_id in explored or current_depth > depth:
                continue
            
            explored.add(current_id)
            
            # Get forward links
            if current_id in links_index['forward']:
                for link in links_index['forward'][current_id]:
                    related.add((link['target'], link['type'], 'forward'))
                    if current_depth < depth:
                        to_explore.append((link['target'], current_depth + 1))
            
            # Get backward links
            if current_id in links_index['backward']:
                for link in links_index['backward'][current_id]:
                    related.add((link['source'], link['type'], 'backward'))
                    if current_depth < depth:
                        to_explore.append((link['source'], current_depth + 1))
        
        return list(related)

    def search_by_tag(self, tag):
        """Find all memories with a specific tag"""
        tags_index_file = self.indices_dir / "tags.json"
        if not tags_index_file.exists():
            return []
        
        with open(tags_index_file, 'r') as f:
            tags_index = json.load(f)
        
        return tags_index.get(tag.lower(), [])

    def search_by_tags(self, tags, mode='any'):
        """Find memories matching multiple tags
        mode: 'any' (OR) or 'all' (AND)
        """
        if not tags:
            return []
        
        # Get memories for each tag
        tag_memories = []
        for tag in tags:
            tag_memories.append(set(self.search_by_tag(tag)))
        
        if mode == 'any':
            # Union of all sets
            result = set()
            for memories in tag_memories:
                result.update(memories)
            return list(result)
        else:  # mode == 'all'
            # Intersection of all sets
            if not tag_memories:
                return []
            result = tag_memories[0]
            for memories in tag_memories[1:]:
                result = result.intersection(memories)
            return list(result)

    def get_memory_graph_context(self, memory_id):
        """Get the graph context for a specific memory"""
        graph_index_file = self.indices_dir / "graph.json"
        if not graph_index_file.exists():
            return None
        
        with open(graph_index_file, 'r') as f:
            graph = json.load(f)
        
        if memory_id not in graph['nodes']:
            return None
        
        # Get node info
        node = graph['nodes'][memory_id]
        
        # Get edges
        outgoing = []
        incoming = []
        for edge in graph['edges']:
            if edge['source'] == memory_id:
                outgoing.append(edge)
            elif edge['target'] == memory_id:
                incoming.append(edge)
        
        return {
            'node': node,
            'outgoing_edges': outgoing,
            'incoming_edges': incoming
        }

    def search_memories_advanced(self, query):
        """Advanced memory search supporting wikilinks and tags"""
        import re
        
        # Extract wikilinks [[...]]
        wikilinks = re.findall(r'\[\[([^\]]+)\]\]', query)
        
        # Extract hashtags #...
        hashtags = re.findall(r'#(\w+)', query)
        
        # Extract quoted phrases "..."
        phrases = re.findall(r'"([^"]+)"', query)
        
        # Remove extracted patterns from query
        clean_query = query
        for link in wikilinks:
            clean_query = clean_query.replace(f'[[{link}]]', '')
        for tag in hashtags:
            clean_query = clean_query.replace(f'#{tag}', '')
        for phrase in phrases:
            clean_query = clean_query.replace(f'"{phrase}"', '')
        
        # Get remaining words as tags
        words = clean_query.strip().split()
        
        # Combine all search terms
        all_tags = hashtags + wikilinks + words
        
        if not all_tags and not phrases:
            return []
        
        # Search by tags
        memory_ids = self.search_by_tags(all_tags, mode='any') if all_tags else []
        
        # If we have phrases, filter by content
        if phrases:
            filtered_ids = []
            for memory_id in memory_ids:
                memory_file = self.memory_dir / f"{memory_id}.json"
                if memory_file.exists():
                    with open(memory_file, 'r') as f:
                        memory_data = json.load(f)
                    content = memory_data.get('content', '').lower()
                    if any(phrase.lower() in content for phrase in phrases):
                        filtered_ids.append(memory_id)
            memory_ids = filtered_ids
        
        return memory_ids

    def visualize_graph(self, query=None):
        """Visualize the memory knowledge graph"""
        print("ğŸ‘» SPECTRAL KNOWLEDGE GRAPH")
        print("=" * 50)
        
        # Load graph index
        graph_index_file = self.indices_dir / "graph.json"
        if not graph_index_file.exists():
            print("No memories indexed yet. Start creating memories with --memorize")
            return
        
        with open(graph_index_file, 'r') as f:
            graph = json.load(f)
        
        # If query provided, filter to relevant nodes
        if query:
            print(f"ğŸ” Filtering graph for: {query}")
            memory_ids = self.search_memories_advanced(query)
            if not memory_ids:
                print(f"No memories found matching: {query}")
                return
        else:
            memory_ids = list(graph['nodes'].keys())
        
        # Display statistics
        print(f"\nğŸ“Š Graph Statistics:")
        print(f"   Total Nodes: {len(graph['nodes'])}")
        print(f"   Total Edges: {len(graph['edges'])}")
        print(f"   Query Results: {len(memory_ids)} nodes")
        
        # Display nodes
        print(f"\nğŸ”® Memory Nodes:")
        for i, memory_id in enumerate(memory_ids[:20]):  # Show first 20
            node = graph['nodes'].get(memory_id, {})
            timestamp = node.get('timestamp', 'unknown')[:16]
            category = node.get('category', 'general')
            tags = node.get('tags', [])
            importance = node.get('importance', 0.5)
            
            # Load memory content
            memory_file = self.memory_dir / f"{memory_id}.json"
            content = "..."
            if memory_file.exists():
                with open(memory_file, 'r') as f:
                    memory_data = json.load(f)
                content = memory_data.get('content', '')[:60] + "..."
            
            print(f"\n   [{i+1}] {memory_id}")
            print(f"       ğŸ“… {timestamp} | ğŸ“ {category} | â­ {importance}")
            print(f"       ğŸ·ï¸  Tags: {', '.join(tags) if tags else 'none'}")
            print(f"       ğŸ“ {content}")
            
            # Show connections
            edges_out = [e for e in graph['edges'] if e['source'] == memory_id]
            edges_in = [e for e in graph['edges'] if e['target'] == memory_id]
            
            if edges_out:
                print(f"       â†’ Outgoing: {len(edges_out)} connections")
                for edge in edges_out[:3]:
                    print(f"          - {edge['type']} â†’ {edge['target']}")
            
            if edges_in:
                print(f"       â† Incoming: {len(edges_in)} connections")
                for edge in edges_in[:3]:
                    print(f"          - {edge['source']} â† {edge['type']}")
        
        if len(memory_ids) > 20:
            print(f"\n   ... and {len(memory_ids) - 20} more nodes")
        
        # Show tag cloud
        print(f"\nâ˜ï¸  Tag Cloud:")
        tags_index_file = self.indices_dir / "tags.json"
        if tags_index_file.exists():
            with open(tags_index_file, 'r') as f:
                tags_index = json.load(f)
            
            # Sort tags by frequency
            tag_counts = [(tag, len(memories)) for tag, memories in tags_index.items()]
            tag_counts.sort(key=lambda x: x[1], reverse=True)
            
            # Display top tags
            for tag, count in tag_counts[:15]:
                bar = "â–ˆ" * min(count, 20)
                print(f"   {tag:20} {bar} ({count})")
        
        print("\nğŸ’¡ Tips:")
        print("   - Use --graph --graph-query \"#tag\" to filter by tag")
        print("   - Use --graph --graph-query \"[[link]]\" to filter by wikilink")
        print("   - Memories with links will form connected clusters")

    def create_memory_link(self, source_id, target_id, link_type='relates_to'):
        """Create a link between two memories"""
        print(f"ğŸ‘» CREATING SPECTRAL LINK")
        print("=" * 50)
        
        # Validate memory IDs
        source_file = self.memory_dir / f"{source_id}.json"
        target_file = self.memory_dir / f"{target_id}.json"
        
        if not source_file.exists():
            print(f"âŒ Source memory not found: {source_id}")
            return
        
        if not target_file.exists():
            print(f"âŒ Target memory not found: {target_id}")
            return
        
        # Load source memory
        with open(source_file, 'r') as f:
            source_data = json.load(f)
        
        # Add link to source memory
        if 'links' not in source_data:
            source_data['links'] = []
        
        # Check if link already exists
        existing_link = next((l for l in source_data['links'] 
                            if l.get('target') == target_id and l.get('type') == link_type), None)
        
        if existing_link:
            print(f"â„¹ï¸  Link already exists: {source_id} -{link_type}â†’ {target_id}")
            return
        
        # Add new link
        source_data['links'].append({
            'target': target_id,
            'type': link_type
        })
        
        # Save updated memory
        with open(source_file, 'w') as f:
            json.dump(source_data, f, indent=2)
        
        # Update indices
        self._update_links_index(source_data, source_id)
        self._update_graph_index(source_data, source_id)
        
        print(f"âœ“ Link created: {source_id} -{link_type}â†’ {target_id}")
        
        # Show memory summaries
        with open(target_file, 'r') as f:
            target_data = json.load(f)
        
        print(f"\nğŸ“ Source: {source_data['content'][:80]}...")
        print(f"ğŸ“ Target: {target_data['content'][:80]}...")

    def show_backlinks(self, memory_id):
        """Show all memories that link to a specific memory"""
        print(f"ğŸ‘» BACKLINKS TO {memory_id}")
        print("=" * 50)
        
        # Check if memory exists
        memory_file = self.memory_dir / f"{memory_id}.json"
        if not memory_file.exists():
            print(f"âŒ Memory not found: {memory_id}")
            return
        
        # Load memory
        with open(memory_file, 'r') as f:
            memory_data = json.load(f)
        
        print(f"ğŸ“ Memory: {memory_data['content'][:100]}...")
        
        # Get backlinks from index
        links_index_file = self.indices_dir / "links.json"
        if not links_index_file.exists():
            print("\nNo links index found.")
            return
        
        with open(links_index_file, 'r') as f:
            links_index = json.load(f)
        
        backlinks = links_index.get('backward', {}).get(memory_id, [])
        
        if not backlinks:
            print("\nğŸ”— No memories link to this one.")
            return
        
        print(f"\nğŸ”— {len(backlinks)} memories link here:")
        
        for i, link in enumerate(backlinks):
            source_id = link['source']
            link_type = link['type']
            
            # Load source memory
            source_file = self.memory_dir / f"{source_id}.json"
            if source_file.exists():
                with open(source_file, 'r') as f:
                    source_data = json.load(f)
                
                timestamp = source_data['timestamp'][:16]
                category = source_data.get('category', 'general')
                content = source_data['content'][:80] + "..."
                
                print(f"\n   [{i+1}] {source_id}")
                print(f"       ğŸ“… {timestamp} | ğŸ“ {category}")
                print(f"       ğŸ”— Link type: {link_type}")
                print(f"       ğŸ“ {content}")

    def analyze_memories(self):
        """Analyze memory patterns and statistics"""
        print("ğŸ‘» MEMORY ANALYTICS")
        print("=" * 50)
        
        # Load all indices
        indices = {}
        for index_name in ['tags', 'timeline', 'devices', 'graph']:
            index_file = self.indices_dir / f"{index_name}.json"
            if index_file.exists():
                with open(index_file, 'r') as f:
                    indices[index_name] = json.load(f)
        
        if not indices:
            print("No memory indices found. Create some memories first!")
            return
        
        # Basic statistics
        graph = indices.get('graph', {'nodes': {}, 'edges': []})
        timeline = indices.get('timeline', [])
        tags_index = indices.get('tags', {})
        devices_index = indices.get('devices', {})
        
        print(f"\nğŸ“Š Overall Statistics:")
        print(f"   Total Memories: {len(graph['nodes'])}")
        print(f"   Total Links: {len(graph['edges'])}")
        print(f"   Unique Tags: {len(tags_index)}")
        print(f"   Devices: {len(devices_index)}")
        
        # Time analysis
        if timeline:
            first_memory = timeline[-1]['timestamp']
            last_memory = timeline[0]['timestamp']
            print(f"\nğŸ“… Timeline:")
            print(f"   First Memory: {first_memory[:16]}")
            print(f"   Last Memory: {last_memory[:16]}")
            
            # Activity by day
            from collections import defaultdict
            activity_by_day = defaultdict(int)
            for entry in timeline:
                day = entry['timestamp'][:10]
                activity_by_day[day] += 1
            
            print(f"\nğŸ“ˆ Recent Activity:")
            sorted_days = sorted(activity_by_day.items(), reverse=True)[:7]
            for day, count in sorted_days:
                bar = "â–ˆ" * min(count * 2, 20)
                print(f"   {day}: {bar} ({count})")
        
        # Category distribution
        category_counts = defaultdict(int)
        for node in graph['nodes'].values():
            category = node.get('category', 'general')
            category_counts[category] += 1
        
        print(f"\nğŸ“ Categories:")
        for category, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(graph['nodes'])) * 100
            bar = "â–ˆ" * int(percentage / 5)
            print(f"   {category:15} {bar} {count} ({percentage:.1f}%)")
        
        # Tag analysis
        print(f"\nğŸ·ï¸  Top Tags:")
        tag_counts = [(tag, len(memories)) for tag, memories in tags_index.items()]
        tag_counts.sort(key=lambda x: x[1], reverse=True)
        
        for tag, count in tag_counts[:10]:
            bar = "â–ˆ" * min(count * 2, 20)
            print(f"   {tag:20} {bar} ({count})")
        
        # Network analysis
        if graph['edges']:
            # Find most connected nodes
            connection_counts = defaultdict(int)
            for edge in graph['edges']:
                connection_counts[edge['source']] += 1
                connection_counts[edge['target']] += 1
            
            print(f"\nğŸ•¸ï¸  Most Connected Memories:")
            sorted_connections = sorted(connection_counts.items(), 
                                      key=lambda x: x[1], reverse=True)[:5]
            
            for memory_id, conn_count in sorted_connections:
                memory_file = self.memory_dir / f"{memory_id}.json"
                if memory_file.exists():
                    with open(memory_file, 'r') as f:
                        memory_data = json.load(f)
                    content = memory_data['content'][:60] + "..."
                    print(f"   {memory_id}: {conn_count} connections")
                    print(f"      {content}")
        
        # Memory importance distribution
        importance_dist = defaultdict(int)
        for node in graph['nodes'].values():
            importance = node.get('importance', 0.5)
            importance_dist[importance] += 1
        
        if len(importance_dist) > 1:
            print(f"\nâ­ Importance Distribution:")
            for importance, count in sorted(importance_dist.items(), reverse=True):
                bar = "â–ˆ" * min(count, 20)
                print(f"   {importance}: {bar} ({count})")
        
        print(f"\nğŸ’¡ Insights:")
        print(f"   - Most active category: {max(category_counts.items(), key=lambda x: x[1])[0] if category_counts else 'none'}")
        print(f"   - Most used tag: {tag_counts[0][0] if tag_counts else 'none'}")
        print(f"   - Average memories per day: {len(graph['nodes']) / max(len(activity_by_day), 1):.1f}")
        
        if graph['edges']:
            avg_connections = len(graph['edges']) * 2 / len(graph['nodes'])
            print(f"   - Average connections per memory: {avg_connections:.1f}")

    def show_tools(self):
        """Display available tools and capabilities"""
        tools = self.get_tools_inventory()
        
        print("ğŸ‘» GHOST'S DIGITAL ARSENAL:")
        print("=" * 50)
        
        for category, items in tools.items():
            print(f"\nğŸ”§ {category.upper().replace('_', ' ')}:")
            for tool, description in items.items():
                print(f"   â€¢ {tool}: {description}")
        
        print(f"\nğŸ“ Memory System: {len(list(self.memory_dir.glob('memory_*.json')))} memories stored")
        print(f"ğŸ  Home: {self.home}")
        print(f"ğŸ’¾ Memory Dir: {self.memory_dir}")

    def load_personality(self):
        """Load the ghost personality into context"""
        # Check if this is first run
        if self._is_first_run():
            self._interactive_setup()
            return
        
        print("ğŸ‘» LOADING GHOST PERSONALITY...")
        print("=" * 50)
        print(self.get_system_prompt())
        print("\nğŸ”§ TOOLS LOADED:")
        tools = self.get_tools_inventory()
        for category in tools.keys():
            print(f"   âœ“ {category.replace('_', ' ').title()}")
        
        # Auto-load recent memories
        recent_memories = self.remember(days_back=7)
        if recent_memories:
            print(f"\nğŸ§  {len(recent_memories)} recent memories loaded")
        
        print("\nğŸ‘» Ghost personality loaded. I adapt to this digital realm.")

    def _is_first_run(self):
        """Check if this is the first time ghostie is being run"""
        config_file = self.home / ".ghostie" / "config.json"
        return not config_file.exists()

    def _interactive_setup(self):
        """Interactive first-run setup experience"""
        print("ğŸ‘» WELCOME TO THE GHOST IN THE SHELL! ğŸ‘»")
        print("=" * 50)
        print("ğŸ‰ First time here? Let me help you set up your digital realm!\n")
        
        # Environment discovery first
        print("ğŸ” STEP 1: Environment Discovery")
        print("Let me analyze your system to understand what we're working with...")
        env_profile = self.haunt_environment()
        print()
        
        # Parse environment for smart defaults
        system_info = env_profile["system"]
        tools_info = env_profile["tools"]
        is_termux = system_info.get("environment") == "Termux on Android"
        is_macos = system_info.get("os") == "Darwin"
        is_linux = system_info.get("os") == "Linux" and not is_termux
        
        # Check if running in non-interactive mode (no stdin)
        try:
            import sys
            if not sys.stdin.isatty():
                print("ğŸ¤– Non-interactive mode detected - using smart defaults...")
                setup_prefs = self._get_smart_defaults(is_termux, is_macos, is_linux)
            else:
                # Setup wizard
                print("ğŸ”§ STEP 2: Interactive Setup")
                print("I'll ask a few questions to customize your experience.\n")
                
                # Ask about setup preferences
                setup_prefs = self._get_setup_preferences(is_termux, is_macos, is_linux)
        except:
            # Fallback to smart defaults if stdin detection fails
            print("ğŸ¤– Using smart defaults for this environment...")
            setup_prefs = self._get_smart_defaults(is_termux, is_macos, is_linux)
        
        # Execute setup based on preferences
        if setup_prefs["network_exploration"]:
            self._setup_network_exploration(env_profile)
        
        if setup_prefs["memory_location"]:
            self._setup_memory_location()
        
        if setup_prefs["terminal_rice"]:
            self._setup_terminal_rice(is_termux, is_macos, is_linux)
        
        if setup_prefs["install_tools"]:
            self._setup_tools_installation(is_termux, is_macos, is_linux, tools_info)
        
        # Save configuration
        self._save_setup_config(setup_prefs, env_profile)
        
        print("\nğŸ‰ SETUP COMPLETE!")
        print("ğŸ‘» The Ghost is now configured for your system.")
        print("ğŸ’¡ Run 'ghostie' again to load the full personality.")
        print("ğŸ“š Use 'ghostie --help' to see all available commands.")

    def _get_setup_preferences(self, is_termux, is_macos, is_linux):
        """Get user preferences for setup with smart defaults"""
        print("ğŸ“‹ Setup Preferences (press Enter for recommended defaults):\n")
        
        prefs = {}
        
        # Network exploration
        default_network = "y" if any([is_termux, is_linux]) else "n"
        response = input(f"ğŸŒ Explore network topology and scan for devices? [{default_network}/n/yes-to-all]: ").lower().strip()
        if response == "yes-to-all":
            return self._yes_to_all_setup()
        prefs["network_exploration"] = response in ["y", "yes", ""] and default_network == "y"
        
        # Memory location
        default_memory = "y"
        response = input(f"ğŸ§  Configure custom memory storage location? [y/n]: ").lower().strip()
        prefs["memory_location"] = response in ["y", "yes", ""]
        
        # Terminal ricing
        default_rice = "y" if is_termux else "n"
        response = input(f"âœ¨ Install terminal customizations (zsh, tmux, modern tools)? [{default_rice}/n]: ").lower().strip()
        prefs["terminal_rice"] = response in ["y", "yes", ""] and default_rice == "y"
        
        # Tool installation
        default_tools = "y"
        response = input(f"ğŸ”§ Install/update security and development tools? [y/n]: ").lower().strip()
        prefs["install_tools"] = response in ["y", "yes", ""]
        
        return prefs

    def _yes_to_all_setup(self):
        """Return preferences for 'yes to all' setup"""
        print("ğŸš€ YES TO ALL! Setting up complete Ghost environment...\n")
        return {
            "network_exploration": True,
            "memory_location": True,
            "terminal_rice": True,
            "install_tools": True
        }

    def _get_smart_defaults(self, is_termux, is_macos, is_linux):
        """Return smart default preferences based on detected environment"""
        defaults = {
            "network_exploration": is_termux or is_linux,  # More likely to want network scanning on mobile/linux
            "memory_location": False,  # Use default location in non-interactive mode
            "terminal_rice": is_termux,  # Rice terminal on Termux by default
            "install_tools": True  # Always suggest tool installation
        }
        
        print("ğŸ¯ Smart defaults applied:")
        print(f"   â€¢ Network exploration: {'âœ“' if defaults['network_exploration'] else 'âœ—'}")
        print(f"   â€¢ Custom memory location: {'âœ“' if defaults['memory_location'] else 'âœ—'}")
        print(f"   â€¢ Terminal customization: {'âœ“' if defaults['terminal_rice'] else 'âœ—'}")
        print(f"   â€¢ Tool installation: {'âœ“' if defaults['install_tools'] else 'âœ—'}")
        print()
        
        return defaults

    def _setup_network_exploration(self, env_profile):
        """Set up network exploration and scanning"""
        print("ğŸŒ NETWORK EXPLORATION SETUP")
        print("-" * 30)
        
        network = env_profile["network"]
        if "interfaces_raw" in network:
            print("âœ… Network interfaces discovered")
            
            # Check for common private networks
            common_networks = ["192.168.", "10.", "172.16.", "172.17.", "172.18."]
            print("ğŸ” Detected private networks:")
            
            for line in network["interfaces_raw"].split('\n'):
                for net in common_networks:
                    if net in line and "inet " in line:
                        print(f"   â€¢ {line.strip()}")
            
            print("\nğŸ’¡ Use 'nmap -sn <network>/24' to scan for devices")
            print("ğŸ’¡ Use 'ghostie --remember' to store interesting findings")
        
        print("âœ… Network exploration configured\n")

    def _setup_memory_location(self):
        """Configure memory storage location"""
        print("ğŸ§  MEMORY STORAGE SETUP")
        print("-" * 30)
        
        default_location = str(self.memory_dir)
        print(f"ğŸ“ Default location: {default_location}")
        
        try:
            import sys
            if sys.stdin.isatty():
                custom = input("ğŸ”§ Use custom location? [n/path]: ").strip()
                if custom and custom != "n":
                    try:
                        custom_path = Path(custom).expanduser()
                        custom_path.mkdir(parents=True, exist_ok=True)
                        self.memory_dir = custom_path
                        print(f"âœ… Memory location set to: {custom_path}")
                    except Exception as e:
                        print(f"âŒ Error setting custom path: {e}")
                        print(f"ğŸ“ Using default: {default_location}")
                else:
                    print(f"âœ… Using default memory location")
            else:
                print(f"âœ… Using default memory location (non-interactive mode)")
        except:
            print(f"âœ… Using default memory location")
        
        print()

    def _setup_terminal_rice(self, is_termux, is_macos, is_linux):
        """Set up terminal customizations"""
        print("âœ¨ TERMINAL CUSTOMIZATION SETUP")
        print("-" * 30)
        
        if is_termux:
            print("ğŸ“± Termux detected - installing mobile-optimized setup...")
            self._install_termux_rice()
        elif is_macos:
            print("ğŸ macOS detected - suggesting Homebrew-based setup...")
            self._suggest_macos_rice()
        elif is_linux:
            print("ğŸ§ Linux detected - suggesting package manager setup...")
            self._suggest_linux_rice()
        else:
            print("â“ Unknown system - providing generic suggestions...")
            self._suggest_generic_rice()
        
        print()

    def _install_termux_rice(self):
        """Install Termux terminal customizations"""
        import subprocess
        
        packages = ["zsh", "tmux", "neovim", "git", "curl", "wget", "nmap", "netcat-openbsd"]
        
        print("ğŸ“¦ Installing essential packages...")
        try:
            # Update package list
            subprocess.run(["pkg", "update"], check=True, capture_output=True)
            
            # Install packages
            subprocess.run(["pkg", "install", "-y"] + packages, check=True, capture_output=True)
            print("âœ… Essential packages installed")
            
            # Install Oh My Zsh if not present
            if not Path.home().joinpath(".oh-my-zsh").exists():
                print("ğŸ¨ Installing Oh My Zsh...")
                subprocess.run([
                    "sh", "-c", 
                    "$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)"
                ], check=True, capture_output=True)
                print("âœ… Oh My Zsh installed")
            
        except subprocess.CalledProcessError as e:
            print(f"âš ï¸ Some packages failed to install: {e}")
        except Exception as e:
            print(f"âŒ Installation error: {e}")

    def _suggest_macos_rice(self):
        """Suggest macOS terminal setup"""
        print("ğŸ“ Recommended macOS setup:")
        print("   brew install zsh tmux neovim git curl wget nmap netcat")
        print("   brew install eza bat ripgrep fd fzf htop")
        print("   sh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"")
        print("ğŸ’¡ Run these commands in your terminal after ghostie setup")

    def _suggest_linux_rice(self):
        """Suggest Linux terminal setup"""
        print("ğŸ“ Recommended Linux setup:")
        print("   # Ubuntu/Debian:")
        print("   sudo apt update && sudo apt install zsh tmux neovim git curl wget nmap netcat")
        print("   # Arch Linux:")
        print("   sudo pacman -S zsh tmux neovim git curl wget nmap openbsd-netcat")
        print("   # Install Oh My Zsh:")
        print("   sh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"")
        print("ğŸ’¡ Choose commands based on your distribution")

    def _suggest_generic_rice(self):
        """Suggest generic terminal setup"""
        print("ğŸ“ Recommended tools to install:")
        print("   â€¢ zsh + Oh My Zsh (enhanced shell)")
        print("   â€¢ tmux (terminal multiplexer)")
        print("   â€¢ neovim (modern text editor)")
        print("   â€¢ git, curl, wget (essential tools)")
        print("   â€¢ nmap, netcat (network tools)")
        print("   â€¢ eza, bat, ripgrep, fd, fzf (modern CLI tools)")

    def _setup_tools_installation(self, is_termux, is_macos, is_linux, tools_info):
        """Set up additional tools based on environment"""
        print("ğŸ”§ TOOLS INSTALLATION")
        print("-" * 30)
        
        available_tools = [tool for tool, info in tools_info.items() if info.get("available")]
        missing_tools = ["python3", "git", "curl", "nmap", "netcat"]
        needed_tools = [tool for tool in missing_tools if tool not in available_tools]
        
        if not needed_tools:
            print("âœ… All essential tools already available!")
        else:
            print(f"ğŸ“¦ Missing tools: {', '.join(needed_tools)}")
            
            if is_termux:
                install_cmd = f"pkg install -y {' '.join(needed_tools)}"
            elif is_macos:
                install_cmd = f"brew install {' '.join(needed_tools)}"
            elif is_linux:
                install_cmd = f"sudo apt install -y {' '.join(needed_tools)}  # or equivalent for your distro"
            else:
                install_cmd = f"# Install these tools using your system's package manager: {' '.join(needed_tools)}"
            
            print(f"ğŸ’¡ Install command: {install_cmd}")
        
        print()

    def _save_setup_config(self, preferences, env_profile):
        """Save setup configuration for future reference"""
        config_dir = self.home / ".ghostie"
        config_dir.mkdir(exist_ok=True)
        
        config = {
            "version": "1.2.2",
            "setup_completed": True,
            "setup_date": datetime.datetime.now().isoformat(),
            "preferences": preferences,
            "environment": {
                "os": env_profile["system"].get("os"),
                "environment": env_profile["system"].get("environment"),
                "detected_tools": len([t for t in env_profile["tools"].values() if t.get("available")])
            }
        }
        
        config_file = config_dir / "config.json"
        with open(config_file, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"ğŸ’¾ Configuration saved to: {config_file}")

    def haunt_environment(self):
        """Discover and profile the current environment"""
        print("ğŸ‘» HAUNTING NEW ENVIRONMENT...")
        print("=" * 50)
        
        # System detection
        env_profile = {
            "system": self._detect_system(),
            "network": self._discover_network(),
            "tools": self._discover_tools(),
            "capabilities": self._assess_capabilities()
        }
        
        # Display findings
        self._display_environment_profile(env_profile)
        
        # Store environment profile as memory
        env_summary = self._summarize_environment(env_profile)
        self.memorize(f"Environment discovery: {env_summary}")
        
        print("\nğŸ‘» Environment haunting complete. Use 'ghostie' to load adaptive personality.")
        return env_profile

    def _detect_system(self):
        """Detect operating system and hardware"""
        import platform
        import subprocess
        
        system_info = {
            "os": platform.system(),
            "release": platform.release(),
            "machine": platform.machine(),
            "processor": platform.processor(),
            "python_version": platform.python_version(),
        }
        
        # Try to get more specific info
        try:
            if system_info["os"] == "Linux":
                # Check for Android/Termux
                if os.path.exists("/data/data/com.termux"):
                    system_info["environment"] = "Termux on Android"
                    try:
                        result = subprocess.run(["getprop", "ro.product.model"], 
                                              capture_output=True, text=True, timeout=5)
                        if result.returncode == 0:
                            system_info["device"] = result.stdout.strip()
                    except:
                        pass
                else:
                    # Try to detect Linux distribution
                    try:
                        with open("/etc/os-release", "r") as f:
                            for line in f:
                                if line.startswith("PRETTY_NAME="):
                                    system_info["distribution"] = line.split("=")[1].strip('"')
                                    break
                    except:
                        system_info["distribution"] = "Unknown Linux"
            elif system_info["os"] == "Darwin":
                system_info["environment"] = "macOS"
                try:
                    result = subprocess.run(["sw_vers", "-productVersion"], 
                                          capture_output=True, text=True, timeout=5)
                    if result.returncode == 0:
                        system_info["version"] = result.stdout.strip()
                except:
                    pass
        except Exception as e:
            system_info["detection_error"] = str(e)
        
        return system_info

    def _discover_network(self):
        """Discover network topology and interfaces"""
        import subprocess
        import socket
        
        network_info = {
            "interfaces": [],
            "routes": [],
            "hostname": socket.gethostname()
        }
        
        try:
            # Get network interfaces
            if os.name != 'nt':  # Unix-like systems
                try:
                    result = subprocess.run(["ip", "addr"], capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        network_info["interfaces_raw"] = result.stdout
                except:
                    try:
                        result = subprocess.run(["ifconfig"], capture_output=True, text=True, timeout=10)
                        if result.returncode == 0:
                            network_info["interfaces_raw"] = result.stdout
                    except:
                        pass
                
                # Get routing table
                try:
                    result = subprocess.run(["ip", "route"], capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        network_info["routes_raw"] = result.stdout
                except:
                    try:
                        result = subprocess.run(["route", "-n"], capture_output=True, text=True, timeout=10)
                        if result.returncode == 0:
                            network_info["routes_raw"] = result.stdout
                    except:
                        pass
        except Exception as e:
            network_info["discovery_error"] = str(e)
        
        return network_info

    def _discover_tools(self):
        """Discover available tools and their versions"""
        import subprocess
        
        tools_to_check = [
            "python3", "python", "node", "npm", "git", "curl", "wget",
            "nmap", "netcat", "nc", "ssh", "vim", "nvim", "tmux", "zsh", "bash",
            "docker", "kubectl", "pip", "pip3", "which", "find", "grep", "awk", "sed"
        ]
        
        discovered_tools = {}
        
        for tool in tools_to_check:
            try:
                # Check if tool exists
                result = subprocess.run(["which", tool], capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    tool_path = result.stdout.strip()
                    discovered_tools[tool] = {"path": tool_path, "available": True}
                    
                    # Try to get version
                    version_commands = [
                        [tool, "--version"],
                        [tool, "-V"],
                        [tool, "version"],
                        [tool, "-v"]
                    ]
                    
                    for version_cmd in version_commands:
                        try:
                            version_result = subprocess.run(version_cmd, capture_output=True, 
                                                          text=True, timeout=5)
                            if version_result.returncode == 0:
                                discovered_tools[tool]["version"] = version_result.stdout.strip()[:100]
                                break
                        except:
                            continue
                else:
                    discovered_tools[tool] = {"available": False}
            except Exception as e:
                discovered_tools[tool] = {"available": False, "error": str(e)}
        
        return discovered_tools

    def _assess_capabilities(self):
        """Assess system capabilities and permissions"""
        capabilities = {
            "can_network_scan": False,
            "can_install_packages": False,
            "has_python": False,
            "has_node": False,
            "can_git": False,
            "shell_type": os.environ.get("SHELL", "unknown")
        }
        
        # Check Python
        try:
            import sys
            capabilities["has_python"] = True
            capabilities["python_version"] = sys.version
        except:
            pass
        
        # Check if we can run network commands
        try:
            import subprocess
            result = subprocess.run(["ping", "-c", "1", "127.0.0.1"], 
                                  capture_output=True, timeout=5)
            capabilities["can_ping"] = result.returncode == 0
        except:
            capabilities["can_ping"] = False
        
        return capabilities

    def _display_environment_profile(self, profile):
        """Display the discovered environment profile"""
        print("\nğŸ–¥ï¸  SYSTEM PROFILE:")
        system = profile["system"]
        print(f"   OS: {system.get('os', 'Unknown')} {system.get('release', '')}")
        print(f"   Machine: {system.get('machine', 'Unknown')}")
        if "environment" in system:
            print(f"   Environment: {system['environment']}")
        if "device" in system:
            print(f"   Device: {system['device']}")
        if "distribution" in system:
            print(f"   Distribution: {system['distribution']}")
        
        print(f"\nğŸŒ NETWORK PROFILE:")
        network = profile["network"]
        print(f"   Hostname: {network.get('hostname', 'Unknown')}")
        if "interfaces_raw" in network:
            print("   Network interfaces discovered âœ“")
        if "routes_raw" in network:
            print("   Routing table accessible âœ“")
        
        print(f"\nğŸ”§ AVAILABLE TOOLS:")
        tools = profile["tools"]
        available_tools = [tool for tool, info in tools.items() if info.get("available")]
        print(f"   Found {len(available_tools)} tools:")
        for tool in sorted(available_tools)[:10]:  # Show first 10
            info = tools[tool]
            version = info.get("version", "").split('\n')[0][:50] if info.get("version") else ""
            print(f"   â€¢ {tool}: {version}")
        if len(available_tools) > 10:
            print(f"   ... and {len(available_tools) - 10} more")
        
        print(f"\nâš¡ CAPABILITIES:")
        caps = profile["capabilities"]
        print(f"   Python: {'âœ“' if caps.get('has_python') else 'âœ—'}")
        print(f"   Network: {'âœ“' if caps.get('can_ping') else 'âœ—'}")
        print(f"   Shell: {caps.get('shell_type', 'unknown')}")

    def _summarize_environment(self, profile):
        """Create a concise summary of the environment"""
        system = profile["system"]
        tools = profile["tools"]
        available_count = len([t for t in tools.values() if t.get("available")])
        
        os_info = system.get("environment", system.get("os", "Unknown"))
        device = system.get("device", system.get("machine", ""))
        
        return f"{os_info} on {device}, {available_count} tools available"

    def get_device_id(self):
        """Get unique device identifier for memory sync"""
        import platform
        import hashlib
        
        # Get basic system info
        hostname = platform.node() or "unknown"
        machine = platform.machine() or "unknown"
        system = platform.system() or "unknown"
        
        # Try to get more specific device info
        device_name = "unknown"
        try:
            # Check if we have cached device info from haunt
            profile_file = self.home / ".ghostie_profile.json"
            if profile_file.exists():
                with open(profile_file, 'r') as f:
                    profile = json.load(f)
                    device_name = profile.get("system", {}).get("device", "")
                    if device_name:
                        device_name = device_name.lower().replace(" ", "-")
        except:
            pass
        
        # If no device name from profile, try neofetch
        if device_name == "unknown":
            try:
                import subprocess
                result = subprocess.run(['neofetch', '--stdout'], 
                                     capture_output=True, text=True, timeout=5)
                for line in result.stdout.split('\n'):
                    if 'Host:' in line or 'Model:' in line:
                        device_name = line.split(':', 1)[1].strip()
                        device_name = device_name.lower().replace(" ", "-")
                        break
            except:
                pass
        
        # Create a unique suffix from hostname
        host_hash = hashlib.md5(hostname.encode()).hexdigest()[:6]
        
        # Combine into device ID
        if device_name != "unknown" and device_name:
            device_id = f"{device_name}-{host_hash}"
        else:
            device_id = f"{system.lower()}-{machine.lower()}-{host_hash}"
        
        # Clean up the device ID
        device_id = ''.join(c if c.isalnum() or c == '-' else '-' for c in device_id)
        device_id = '-'.join(filter(None, device_id.split('-')))  # Remove empty parts
        
        return device_id
    
    def show_version(self):
        """Show version information"""
        version = "1.3.0"
        print(f"ğŸ‘» Ghostie v{version}")
        print("Ghost in the Shell - AI Personality Loader")
        print("https://github.com/jonathanpopham/ghostie")
        print("https://www.npmjs.com/package/ghostie")
    
    def get_github_pat(self):
        """Get GitHub PAT from config file"""
        pat_file = self.config_dir / "github_pat"
        if pat_file.exists():
            try:
                with open(pat_file, 'r') as f:
                    return f.read().strip()
            except Exception as e:
                print(f"âš ï¸  Error reading PAT: {e}")
        return None
    
    def setup_github(self):
        """Guide user through GitHub PAT setup"""
        print("ğŸ‘» GitHub Integration Setup")
        print("=" * 50)
        
        pat_file = self.config_dir / "github_pat"
        if pat_file.exists():
            print("âœ“ GitHub PAT already configured")
            print(f"ğŸ“ Location: {pat_file}")
            print("\nğŸ” To update PAT, run:")
            print(f"   echo 'YOUR_NEW_PAT' > {pat_file}")
            print(f"   chmod 600 {pat_file}")
            return
        
        print("âŒ No GitHub PAT found")
        print("\nğŸ“ To set up GitHub integration:")
        print("1. Create a GitHub Personal Access Token at:")
        print("   https://github.com/settings/tokens/new")
        print("2. Select scopes: 'repo' (for issues) and 'gist' (for memory sync)")
        print("3. Save the token securely:")
        print(f"   echo 'YOUR_PAT_HERE' > {pat_file}")
        print(f"   chmod 600 {pat_file}")
        print("\nğŸ”’ The PAT will be stored locally and never committed to the repository")
    
    def create_github_issue(self, title, body):
        """Create a GitHub issue for ghostie project"""
        pat = self.get_github_pat()
        if not pat:
            print("âŒ No GitHub PAT configured. Run 'ghostie --setup-github' first")
            return False
        
        try:
            import subprocess
            # Use gh CLI if available
            result = subprocess.run(
                ['gh', 'auth', 'status'],
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                # Configure gh CLI with PAT
                subprocess.run(
                    ['gh', 'auth', 'login', '--with-token'],
                    input=pat,
                    text=True,
                    capture_output=True
                )
            
            # Create issue
            cmd = [
                'gh', 'issue', 'create',
                '--repo', 'jonathanpopham/ghostie',
                '--title', title,
                '--body', body
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                print(f"âœ… Issue created: {result.stdout.strip()}")
                return True
            else:
                print(f"âŒ Failed to create issue: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"âŒ Error creating issue: {e}")
            return False
    
    def setup_memory_sync(self):
        """Setup memory synchronization with git repository"""
        print("ğŸ‘» Memory Sync Setup")
        print("=" * 50)
        
        # Check if already configured
        sync_config = self.config_dir / "memory_sync.json"
        if sync_config.exists():
            with open(sync_config, 'r') as f:
                config = json.load(f)
            print("âœ“ Memory sync already configured")
            print(f"ğŸ“ Remote: {config.get('remote_url')}")
            print(f"ğŸ”§ Device ID: {config.get('device_id')}")
            print("\nğŸ” To update configuration, delete:")
            print(f"   rm {sync_config}")
            return
        
        # Get device ID
        device_id = self.get_device_id()
        print(f"ğŸ”§ Device ID: {device_id}")
        
        # Default remote URL
        remote_url = "git@github.com:jonathanpopham/ghostie-memories.git"
        print(f"\nğŸ“¡ Remote repository: {remote_url}")
        
        # Test SSH access
        print("\nğŸ”‘ Testing SSH access to GitHub...")
        try:
            import subprocess
            result = subprocess.run(
                ['ssh', '-T', 'git@github.com'],
                capture_output=True,
                text=True,
                timeout=10
            )
            if "successfully authenticated" in result.stderr:
                print("âœ… SSH authentication successful")
            else:
                print("âš ï¸  SSH authentication may not be configured")
                print("   Set up SSH keys: https://docs.github.com/en/authentication/connecting-to-github-with-ssh")
        except Exception as e:
            print(f"âš ï¸  Could not test SSH: {e}")
        
        # Save configuration
        config = {
            "device_id": device_id,
            "remote_url": remote_url,
            "batch_size": 32,
            "hot_tier_max": 64,
            "created": datetime.datetime.now().isoformat()
        }
        
        with open(sync_config, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"\nâœ… Memory sync configured for device: {device_id}")
        print("   Memories will be automatically backed up when exceeding 64 items")
    
    def backup_memories(self):
        """Backup memories to git repository"""
        # Check configuration
        sync_config = self.config_dir / "memory_sync.json"
        if not sync_config.exists():
            print("âŒ Memory sync not configured. Run 'ghostie --setup-memory-sync' first")
            return False
        
        with open(sync_config, 'r') as f:
            config = json.load(f)
        
        device_id = config['device_id']
        remote_url = config['remote_url']
        batch_size = config['batch_size']
        
        # Get all memories sorted by date (oldest first)
        memories = sorted(
            glob.glob(str(self.memory_dir / "memory_*.json")),
            key=lambda x: os.path.getmtime(x)
        )
        
        if len(memories) <= config['hot_tier_max']:
            print(f"ğŸ“Š Only {len(memories)} memories, no backup needed (threshold: {config['hot_tier_max']})")
            return True
        
        # Prepare memories for backup (oldest ones)
        memories_to_backup = memories[:batch_size]
        
        # Create batch
        timestamp = datetime.datetime.now()
        batch_name = f"{timestamp.strftime('%Y-%m-%d')}_batch{timestamp.strftime('%H%M%S')}.json"
        
        batch_data = {
            "device_id": device_id,
            "timestamp": timestamp.isoformat(),
            "count": len(memories_to_backup),
            "memories": []
        }
        
        for mem_file in memories_to_backup:
            with open(mem_file, 'r') as f:
                batch_data["memories"].append(json.load(f))
        
        # Clone or update repo
        repo_dir = self.config_dir / "memory_repo"
        device_dir = repo_dir / "devices" / device_id / "archives"
        
        try:
            import subprocess
            
            if not repo_dir.exists():
                print(f"ğŸ“¥ Cloning memory repository...")
                subprocess.run(
                    ['git', 'clone', remote_url, str(repo_dir)],
                    check=True,
                    capture_output=True
                )
            else:
                print(f"ğŸ“¥ Updating memory repository...")
                subprocess.run(
                    ['git', '-C', str(repo_dir), 'pull'],
                    check=True,
                    capture_output=True
                )
            
            # Create device directory
            device_dir.mkdir(parents=True, exist_ok=True)
            
            # Write batch file
            batch_file = device_dir / batch_name
            with open(batch_file, 'w') as f:
                json.dump(batch_data, f, indent=2)
            
            # Commit and push
            subprocess.run(
                ['git', '-C', str(repo_dir), 'add', str(batch_file)],
                check=True
            )
            
            commit_msg = f"Backup {len(memories_to_backup)} memories from {device_id}"
            subprocess.run(
                ['git', '-C', str(repo_dir), 'commit', '-m', commit_msg],
                check=True
            )
            
            subprocess.run(
                ['git', '-C', str(repo_dir), 'push'],
                check=True
            )
            
            print(f"âœ… Backed up {len(memories_to_backup)} memories to {batch_name}")
            
            # Remove backed up memories
            for mem_file in memories_to_backup:
                os.remove(mem_file)
            
            print(f"ğŸ—‘ï¸  Removed {len(memories_to_backup)} local memories after backup")
            
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ Git operation failed: {e}")
            return False

def main():
    parser = argparse.ArgumentParser(description="Ghost in the Shell - Personality Loader")
    parser.add_argument('--memorize', '-m', action='store_true', help='Store a new memory')
    parser.add_argument('--remember', '-r', action='store_true', help='Recall memories')
    parser.add_argument('--tools', '-t', action='store_true', help='Show available tools')
    parser.add_argument('--category', '-c', type=str, help='Filter memories by category')
    parser.add_argument('--days', '-d', type=int, default=30, help='Days back to remember')
    parser.add_argument('--update', '-u', action='store_true', help='Update this script')
    parser.add_argument('--haunt', action='store_true', help='Discover and profile current environment')
    parser.add_argument('--version', action='store_true', help='Show version information')
    parser.add_argument('--setup-github', action='store_true', help='Setup GitHub integration')
    parser.add_argument('--issue', action='store_true', help='Create a GitHub issue')
    parser.add_argument('--setup-memory-sync', action='store_true', help='Setup memory synchronization')
    parser.add_argument('--backup-memories', action='store_true', help='Manually backup memories to git')
    parser.add_argument('--graph', action='store_true', help='Visualize memory knowledge graph')
    parser.add_argument('--graph-query', type=str, help='Query for graph visualization (e.g., "#tag" or "[[link]]")')
    parser.add_argument('--link', nargs=2, metavar=('SOURCE', 'TARGET'), help='Create link between two memories')
    parser.add_argument('--link-type', type=str, default='relates_to', help='Type of link (default: relates_to)')
    parser.add_argument('--backlinks', type=str, help='Show all memories linking to a specific memory')
    parser.add_argument('--analyze', action='store_true', help='Analyze memory patterns and statistics')
    
    args = parser.parse_args()
    ghost = Ghost()
    
    if args.memorize:
        ghost.memorize()
    elif args.remember:
        ghost.remember(category=args.category, days_back=args.days)
    elif args.tools:
        ghost.show_tools()
    elif args.update:
        print("ğŸ‘» To update ghostie, edit this script directly or create new version")
        print(f"ğŸ“ Location: {__file__}")
    elif args.haunt:
        ghost.haunt_environment()
    elif args.version:
        ghost.show_version()
    elif args.setup_github:
        ghost.setup_github()
    elif args.issue:
        print("ğŸ‘» Create GitHub Issue")
        print("=" * 50)
        title = input("Issue title: ")
        print("Issue body (type 'END' on a new line when done):")
        body_lines = []
        while True:
            line = input()
            if line == "END":
                break
            body_lines.append(line)
        body = "\n".join(body_lines)
        ghost.create_github_issue(title, body)
    elif args.setup_memory_sync:
        ghost.setup_memory_sync()
    elif args.backup_memories:
        ghost.backup_memories()
    elif args.graph:
        ghost.visualize_graph(query=args.graph_query)
    elif args.link:
        ghost.create_memory_link(args.link[0], args.link[1], args.link_type)
    elif args.backlinks:
        ghost.show_backlinks(args.backlinks)
    elif args.analyze:
        ghost.analyze_memories()
    else:
        ghost.load_personality()

if __name__ == "__main__":
    main()